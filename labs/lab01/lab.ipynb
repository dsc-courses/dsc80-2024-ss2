{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 ‚Äì Python, NumPy, and Pandas\n",
    "\n",
    "## DSC 80, Summer 2024\n",
    "\n",
    "### Due Date: Friday, August 9th at 11:59PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Welcome to the first assignment in DSC 80 this quarter!\n",
    "\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding will be done in an accompanying `lab.py` file that is imported into the current notebook, and **you will only submit that `lab.py` file**, not this notebook!\n",
    "\n",
    "Some additional guidelines:\n",
    "- **Unlike in DSC 10, labs will have both public tests and hidden tests.** The bulk of your grade will come from your scores on hidden tests, which you will only see on Gradescope after the assignment deadline.\n",
    "- **Do not change the function names in the `lab.py` file!** The functions in the `lab.py` file are how your assignment is graded, and they are graded by their name. If you changed something you weren't supposed to, you can find the original code in the [course GitHub repository](https://github.com/dsc-courses/dsc80-2024-ss2).\n",
    "- Notebooks are nice for testing and experimenting with different implementations before designing your function in your `lab.py` file. You can write code here, but make sure that all of your real work is in the `lab.py` file, since that's all you're submitting.\n",
    "- You are encouraged to write your own additional helper functions to solve the lab, as long as they also end up in `lab.py`.\n",
    "\n",
    "**To ensure that all of the work you want to submit is in `lab.py`, we've included a script named `lab-validation.py` in the lab folder. You shouldn't edit it, but instead, you should call it from the command line (e.g. the Terminal) to test your work.** More details on its usage are given at the bottom of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing code from `lab.py`**:\n",
    "\n",
    "* Below, we import the `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infrastructure Summary\n",
    "\n",
    "Run the following cell to see a [video üé•](https://www.loom.com/share/0ea254b85b2745e59322b5e5a8692e91?sid=b77c5c2d-0c24-40fb-8cfc-8574d49d9019) that summarizes the above information and walks you through how to\n",
    "- set up your programming environment (see the instructions in [Tech Support](https://dsc80.com/tech_support) for more details),\n",
    "- access assignments,\n",
    "- work on and test assignments, and\n",
    "- submit assignments.\n",
    "\n",
    "The video is also linked on the [Resources tab of the course website](https://dsc80.com/resources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src=\"https://www.loom.com/embed/0ea254b85b2745e59322b5e5a8692e91\", width=750, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started! üéâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Python Basics üêç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 0 ‚Äì Consecutive Integers\n",
    "\n",
    "Complete the implementation of the function `consecutive_ints`, which takes in a possibly empty list of integers (`ints`) and returns `True` if there exist two adjacent list elements that are consecutive integers and `False` otherwise.\n",
    "\n",
    "For example, since `9` is next to `8`, `consecutive_ints([5, 3, 6, 4, 9, 8])` should evaluate to `True`, since `9` and `8` are consecutive integers. On the other hand, `consecutive_ints([1, 3, 5, 7, 9])` should evaluate to `False`.\n",
    "\n",
    "***Note***: If you look at `lab.py`, you'll notice that the solution to this problem is already there. This question is done for you to show you what a completed homework problem looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The cells below are here for you to write scratch work in. \n",
    "# You should write the code for your answer in `lab.py`, not here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the public tests on your code for a given question, run the cell containing a call to `grader.check` that immediately follows it. \n",
    "\n",
    "Remember, your grade will primarily be determined by hidden tests, which are **not** run when you run `grader.check`, so it's important to extensively test your functions on your own by calling them on different inputs. Does they work for edge cases? Real-world data is **very messy** and you should expect your data processing code to break without thorough testing!\n",
    "\n",
    "You can write custom tests either by calling your functions on different inputs here in the notebook, or by writing doctests in `lab.py`, as you did in DSC 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 ‚Äì Median vs. Mean\n",
    "\n",
    "Complete the implementation of the function `median_vs_mean`, which takes in a non-empty list of numbers (`nums`) and returns `True` if median of the list is less than or equal to the mean of the list and `False` otherwise.\n",
    "\n",
    "Recall, if a list has even length, the median is the mean of the middle two elements.\n",
    "\n",
    "***Note:*** In this question, you may only use built-in functions and methods in Python. You should not use `numpy` or `pandas` at all, nor should you import any additional packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Strings and Files üßµ\n",
    "\n",
    "The following questions will familiarize you with the basics of working with strings and reading data from files. Remember that by default, data from files are stored as strings in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 ‚Äì $n$ Prefixes\n",
    "\n",
    "Complete the implementation of the function `n_prefixes`, which takes a string `s` and a positive integer `n`. It returns a string containing the first `n` consecutive prefixes of `s` in reverse order.\n",
    "\n",
    "For example, let's suppose `s` is the string `'Billy!'` and `n` is `4`. The consecutive prefixes of `'Billy!'` are:\n",
    "- `'B'`\n",
    "- `'Bi'`\n",
    "- `'Bil'`\n",
    "- `'Bill'`\n",
    "- `'Billy'`\n",
    "- `'Billy!'`\n",
    "\n",
    "The first 4 of these are `'B'`, `'Bi'`, `'Bil'`, and `'Bill'`. If we combine these 4 in reverse order, we get `'BillBilBiB'`, which is what `n_prefixes('Billy!', 4)` should return. As another example, `n_prefixes('Marina', 3)` should return `'MarMaM'`. **You may assume that `n` is no larger than the length of `s`.**\n",
    "\n",
    "***Hint:*** Recall that [strings may be sliced](https://docs.python.org/3/tutorial/introduction.html#strings), like lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 ‚Äì Exploded Numbers üí£\n",
    "\n",
    "Complete the implementation of the function `exploded_numbers`, which takes in a list of integers (`ints`) and a non-negative integer (`n`) and **returns a list of strings** containing numbers from the list expanded by `n` numbers in both directions, separated by spaces. Each integer should be [zero padded](https://www.tutorialspoint.com/python/string_zfill.htm) so that all integers outputted have the same length.\n",
    "\n",
    "For example, consider `exploded_numbers([3, 8, 15], 2)`.\n",
    "- If we explode 3 by 2 numbers in both directions, we get 1, 2, 3, 4, 5.\n",
    "- If we explode 8 by 2 numbers in both directions, we get 6, 7, 8, 9, 10.\n",
    "- If we explode 15 by 2 numbers in both directions, we get 13, 14, 15, 16, 17.\n",
    "\n",
    "The longest length of any of the exploded numbers above is 2, so all of the outputted integers should have length 2.\n",
    "\n",
    "- The string corresponding to 3 in the input is `'01 02 03 04 05'`.\n",
    "- The string corresponding to 8 in the input is `'06 07 08 09 10'`.\n",
    "- The string corresponding to 15 in the input is `'13 14 15 16 17'`.\n",
    "\n",
    "So, `exploded_numbers([3, 8, 15], 2)` should return `['01 02 03 04 05', '06 07 08 09 10', '13 14 15 16 17']`. \n",
    "\n",
    "As another example, `exploded_numbers([9, 99], 3)` should return `['006 007 008 009 010 011 012', '096 097 098 099 100 101 102']`.\n",
    "\n",
    "***Note***: You can assume that negative numbers will never be encountered. That is, when testing your code, we will never explode a number so much that it becomes negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 ‚Äì Reading Files\n",
    "\n",
    "[Recall](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files) that the built-in function `open` takes in a file path and returns *a file object* (sometimes called a *file handle*). Below are a few properties of file objects:\n",
    "\n",
    "* `open(path)` opens the file at location `path` for reading.\n",
    "* `open(path)` is an *iterable*, which contains successive lines of the file.\n",
    "* Once a file object is opened, after use it should be closed to avoid memory leaks. To ensure a file is closed once done, you should use a *context manager* as follows:\n",
    "```py\n",
    "with open(path) as fh:\n",
    "    for line in fh:\n",
    "        process_line(line)\n",
    "```\n",
    "* To read the entire file into a string, use the `read` method:\n",
    "```py\n",
    "with open(path) as fh:\n",
    "    s = fh.read()\n",
    "```\n",
    "\n",
    "However, you should be careful when reading an entire file into memory that the file isn't too big! *You should avoid this whenever possible!*\n",
    "\n",
    "Complete the implementation of the function `last_chars`, which takes in file object (`fh`) and returns a string consisting of the last character of each line. Note that you don't have to use `open` at all; the argument given to you is a file object, not a file path.\n",
    "\n",
    "***Note:*** A newline (`'\\n'`) is the \"delimiter\" of the lines of a file, and doesn't count as part of the line (as the tests imply). Every other character is part of the line. For more info on this, see [the interpretation](https://en.wikipedia.org/wiki/Newline#Interpretation) of files as a 'newline delimited variables' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, you should see `'hrg'` when running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You'll see the Path(...) / syntax a lot.\n",
    "# It creates the correct path to your file, \n",
    "# whether you're using Windows, macOS, or Linux.\n",
    "# (Note that macOS and Linux use / to denote separate folders in paths,\n",
    "# while Windows uses \\.)\n",
    "\n",
    "fp = Path('data') / 'chars.txt'\n",
    "last_chars(open(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: `numpy` exercises ü•ß\n",
    "\n",
    "For a refresher on `numpy` and arrays, refer to the relevant section of the [DSC 10 course notes](https://notes.dsc10.com/02-data_sets/arrays.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 ‚Äì Array Methods\n",
    "\n",
    "Complete the implementations of the functions `add_root` and `where_square`. Specifications are given below. Your solutions should **not** contain any loops or list comprehensions.\n",
    "\n",
    "#### `add_root`\n",
    "\n",
    "`add_root` should take in a `numpy` array, `A`, and return a new `numpy` array that contains the element-wise sum of the elements in `A` with the _square roots of the positions of the elements in `A`_. \n",
    "\n",
    "For instance, if `A` contains the values 5, 9, and 4, the output array should contain the values 5 (5 + $\\sqrt{0}$), 10 (9 + $\\sqrt{1}$), and 5.4142... (4 + $\\sqrt{2}$).\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `where_square`\n",
    "\n",
    "`where_square` should take in a `numpy` array, `A`, and return a new `numpy` array of Booleans whose `i`th element is `True` if and only if the `i`th element of `A` is a perfect square. \n",
    "\n",
    "For instance, `where_square(np.array([2, 9, 16, 15]))` should return `array([False, True, True, False])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell -- it is needed for the tests to work\n",
    "A_1 = np.array([2, 4, 6, 7])\n",
    "out_1 = add_root(A_1)\n",
    "\n",
    "A_2 = np.array([1, 2, 16, 17, 32, 49])\n",
    "out_2 = where_square(A_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 - Filtering Matrices\n",
    "\n",
    "Complete the implementation for the function `filter_cutoff_loop` and `filter_cutoff_np`.\n",
    "\n",
    "#### Part 1: `filter_cutoff_loop`\n",
    "\n",
    "`filter_cutoff_loop` should take in a matrix (2-dimensional `numpy` array) and a `float` cutoff. The function should return a 2-dimensional `numpy` array with only coumns that have a column mean (strictly) greater than the cutoff value. **This function should be implemented with loops or list comprehensions, not using `numpy` or `pandas` operations.** For example, given the matrix: \n",
    "\n",
    "$$\n",
    "a = \\begin{bmatrix}\n",
    "    1 & -2 & 3 & -3 \\\\\n",
    "    0 & 1 & 3 & 6 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "The column means are computed as follows: \n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1\\\\\n",
    "0\n",
    "\\end{bmatrix} \n",
    "= \\frac{1+0}{2} = 0.5 \\text{, }\n",
    "\\begin{bmatrix}\n",
    "-2\\\\\n",
    "1\n",
    "\\end{bmatrix} \n",
    "= \\frac{-2+1}{2} = 0.5 \\text{, }\n",
    "\\begin{bmatrix}\n",
    "3\\\\\n",
    "3\n",
    "\\end{bmatrix} \n",
    "= \\frac{3+3}{2} = 3 \\text{, }\n",
    "\\begin{bmatrix}\n",
    "-3\\\\\n",
    "6\n",
    "\\end{bmatrix} \n",
    "= \\frac{-3+6}{2} = 1.5\n",
    "$$\n",
    "\n",
    "If the cutoff value is 1, only the last two columns have means above 1, thus only the last two columns are kept, as shown in the first example below. \n",
    "\n",
    "```py\n",
    ">>> a = np.array([[1,-2, 3,-3], [0, 1, 3, 6]])\n",
    ">>> filter_cutoff_loop(a, 1.0)\n",
    "# the column means are [0.1,-0.5, 3, 1.5]\n",
    "# only columns 3 & 4 have column means higher than 1\n",
    "# we only return columns 3 & 4\n",
    "array([[ 3, -3],\n",
    "       [ 3,  6]])\n",
    "```\n",
    "\n",
    "```py\n",
    ">>> a = np.array([[1,-2, 3,-3], [0, 1, 3, 6]])\n",
    ">>> filter_cutoff_loop(a, 2.0)\n",
    "# the column means are [0.1,-0.5, 3, 1.5]\n",
    "# only column 3 has a column mean higher than 2\n",
    "# we only return column 3\n",
    "array([[3],\n",
    "       [3]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "#### Part 2: `filter_cutoff_np`\n",
    "\n",
    "`filter_cutoff_np` should take in the same inputs and output the same results as  `filter_cutoff_loop`.  **Do not use loops or list comprehensions for this implementation, only `numpy` operations.**\n",
    "\n",
    "\n",
    "***Hints:***: \n",
    "- What does the axis argument do in `np.mean`?\n",
    "- Remember we can slice arrays using Boolean values. How does the code below work? \n",
    "```py\n",
    ">>> a = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    ">>> a[:, [True, False, True, False]]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 ‚Äì Stock Prices üìà\n",
    "\n",
    "Complete the implementations of the functions `growth_rates` and `with_leftover`. Specifications are given below. Your solutions should **not** contain any loops or list comprehensions.\n",
    "\n",
    "#### `growth_rates`\n",
    "\n",
    "`growth_rates` should take in a `numpy` array, `A`, of [stock prices](https://en.wikipedia.org/wiki/Stock) for a single stock on successive days in USD. It should return an array of growth rates. That is, the `i`th number of the returned array should contain the rate of growth in stock price between the $i^{th}$ day to the $(i+1)^{th}$ day. The growth rate between two values is defined as $\\frac{\\text{final} - \\text{initial}}{\\text{initial}}$. You should return growth rates as **proportions, rounded to two decimal places**.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `with_leftover`\n",
    "\n",
    "Again, suppose `A` is a `numpy` array of stock prices. Consider the following scheme: \n",
    "\n",
    "- Suppose that you start each day with \\$20 to purchase stocks. \n",
    "- Each day, you purchase as many shares as possible of the stock. (The price changes each day, according to `A`.)\n",
    "- Any money left-over after a given day is saved for possibly buying stock on a future day.\n",
    "\n",
    "The function `with_leftover` should take in `A` and return the day (as an `int`) on which you can buy at least one full share using just \"left-over\" money. If this never happens, return `-1`. Note that the first stock purchase occurs on Day 0, and that you cannot purchase fractions of a share of a stock.\n",
    "\n",
    "For example, if the stock price is \\$3 every day, then the answer is `1` (corresponding to Day 1):\n",
    "- Day 0: Buy 6 stocks with \\\\$20, and \\\\$2 is added to the leftover. Your total leftover is currently \\\\$2. This is not enough to buy one extra share, so you continue.\n",
    "- Day 1: Buy 6 stocks with \\\\$20, and another \\\\$2 is added to the leftover. Your total leftover is now \\\\$4, so you can now buy one extra share. Hence, the answer is Day 1, and `with_leftover` should return `1`.\n",
    "\n",
    "***Hint:*** `np.cumsum` may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell -- it is needed for the tests to work\n",
    "fp = Path('data') / 'stocks.csv'\n",
    "stocks = np.array([float(x) for x in open(fp)])\n",
    "out_3_stocks = growth_rates(stocks)\n",
    "\n",
    "A_4 = np.array([3, 3, 3, 3])\n",
    "out_4 = with_leftover(A_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Introduction to `pandas` üêº\n",
    "\n",
    "This part will help build familiarity with DataFrames in `pandas`. Fortunately, you've already a version of `pandas` before in DSC 10, called `babypandas`! Review the [DSC 10 course notes](https://notes.dsc10.com/02-data_sets/dataframes.html) as necessary.\n",
    "\n",
    "One key difference between `babypandas` and `pandas` is the idiomatic way of accessing a column. In `babypandas`, to access column `'x'` in DataFrame `df`, you used `df.get('x')`. In `pandas`, the more common way is `df['x']`.\n",
    "\n",
    "As always for `pandas` questions:\n",
    "1. Avoid writing loops through the rows of the DataFrame to do the problem, and\n",
    "2. Test the output/correctness of your code with the help of the dataset given, but be sure your code will also run on data that is similar to but different from the dataset given. (One way to do this is to sample rows from the provided DataFrame using the `.sample` method)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `data/salary.csv` contains salary information for the 2021-22 National Basketball Association (NBA) season üèÄ. Specifically, it contains the name, team, and salary of all players who have played at least 15 games last season. We will load this file and store it as a DataFrame named `salary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not edit this cell -- it is needed for the tests\n",
    "salary_fp = Path('data') / 'salary.csv'\n",
    "salary = pd.read_csv(salary_fp)\n",
    "salary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8 ‚Äì `pandas` Basics\n",
    "\n",
    "Your job is to complete the implementation of the function `salary_stats`, which takes in a DataFrame like `salary` and returns a **Series** containing the following statistics:\n",
    "- `'num_players'`: The number of players.\n",
    "- `'num_teams'`: The number of teams.\n",
    "- `'total_salary'`: The total salary amount for all players.\n",
    "- `'highest_salary'`: The name of the player with the highest salary. **Assume there are no ties.**\n",
    "- `'avg_los'`: The average salary of the `'Los Angeles Lakers'`, rounded to two decimal places.\n",
    "- `'fifth_lowest'`: The name and team of the player who has the fifth lowest salary, separated by a comma and a space (e.g. `'Billy Triton, Cleveland Cavaliers'`). **Assume there are no ties.**\n",
    "- `'duplicates'`: A Boolean that is `True` if there are any duplicate last names, and `False` otherwise. Note that some players may have a suffix on their name, such as \"Jr.\" or \"III\" -- you should ignore these. That is, \"Billy Triton Jr.\" and \"Tyler Triton\" should be considered to have the same last name.\n",
    "- `'total_highest'`: The total salary of the team that has the highest paid player.\n",
    "\n",
    "The index of each element in the outputted Series is specified above.\n",
    "\n",
    "***Notes***: \n",
    "- Your function should work on a dataset of the same format that contains information from other years. This means that `salary_stats` should not \"hard-code\" any numbers or strings, but should compute them all programatically. In all cases, you may assume that none of the answers involving ranking involves a tie.\n",
    "- The public tests don't test to see if your function actually returns the right numbers. You should manually inspect your result to make sure that all values seem appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not edit this cell -- it is needed for the tests\n",
    "salary_fp = Path('data') / 'salary.csv'\n",
    "salary = pd.read_csv(salary_fp)\n",
    "stats = salary_stats(salary)\n",
    "\n",
    "salary_sample_fp = Path('data') / 'salary_sample.csv'\n",
    "salary_sample = pd.read_csv(salary_sample_fp)\n",
    "sample_stats = salary_stats(salary_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9 ‚Äì Reading Malformed `.csv` Files\n",
    "\n",
    "`data/malformed.csv` is a file of comma-separated values, containing the following fields:\n",
    "\n",
    "\n",
    "|column name|description|type|\n",
    "|---|---|---|\n",
    "|`'first'`|first name of person|`str`|\n",
    "|`'last'`|last name of person|`str`|\n",
    "|`'weight'`|weight of person (lbs)|`float`|\n",
    "|`'height'`|height of person (in)|`float`|\n",
    "|`'geo'`|location of person; comma-separated latitude/longitude|`str`|\n",
    "\n",
    "Unfortunately, the entries contains errors with the placement of commas (`,`) and quotes (`\"`) that cause `pandas`' `read_csv` function to fail parsing the file with the default settings. Don't believe us? Try using `pd.read_csv` on `data/malformed.csv` and look at what happens.\n",
    "\n",
    "As a result, instead of using `pd.read_csv`, you must read in the file manually using Python's built-in `open` function.\n",
    "\n",
    "Complete the implementation of the function `parse_malformed`, which takes in a file path (`fp`) and returns a parsed, properly-typed DataFrame with the information in the corresponding file. For example, `fp` may be `'data/malformed.csv'`. The DataFrame should contain the columns described in the data description table above (with the specified types).\n",
    "\n",
    "***Note:*** \n",
    "- The only kinds of issues you need your function to handle are comma and quote misplacements; don't try and find any other issues with the CSV. \n",
    "- With that said, you should assume that `data/malformed.csv` is a sample of a larger file that has the same sorts of errors, but potentially in different lines. For example, `data/malformed.csv` has an unnecessary quote `\"` in line 4, but your function may be called on another CSV that has a perfectly fine line 4 but an unnecessary quote on some other line.\n",
    "- So, **don't** implement `parse_malformed` assuming that the commas and quotes are mispositioned on specific lines; rather, implement `parse_malformed` such that it can handle these issues on every single line they appear in.\n",
    "- A good way to proceed is to open `data/malformed.csv` and look carefully at the comma and quote placements.\n",
    "\n",
    "\n",
    "The first few rows of `parse_malformed('data/malformed.csv')` should be:\n",
    "\n",
    "<img src=\"./imgs/example-df.png\" width=45%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not edit -- needed for tests\n",
    "fp = Path('data') / 'malformed.csv'\n",
    "cols = ['first', 'last', 'weight', 'height', 'geo']\n",
    "df = parse_malformed(fp)\n",
    "dg = pd.read_csv(fp, nrows=4, skiprows=10, names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done Lab 1! üèÅ\n",
    "\n",
    "As a reminder, all of the work you want to submit needs to be in `lab.py`.\n",
    "\n",
    "To ensure that all of the work you want to submit is in `lab.py`, we've included a script named `lab-validation.py` in the lab folder. You shouldn't edit it, but instead, you should call it from the command line (e.g. the Terminal) to test your work.\n",
    "\n",
    "Once you've finished the lab, you should open the command line and run, in the directory for this lab:\n",
    "\n",
    "```\n",
    "python lab-validation.py\n",
    "```\n",
    "\n",
    "**This will run all of the `grader.check` cells that you see in this notebook, but only using the code in `lab.py` ‚Äì that is, it doesn't look at any of the code in this notebook. If all of your `grader.check` cells pass in this notebook but not all of them pass in your command line with the above command, then you likely have code in your notebook that isn't in your `lab.py`!**\n",
    "\n",
    "You can also use `lab-validation.py` to test individual questions. For instance,\n",
    "\n",
    "```\n",
    "python lab-validation.py q1 q4 q7 q8\n",
    "```\n",
    "\n",
    "will run the `grader.check` cells for Questions 1, 4, 7, and 8 ‚Äì again, only using the code in `lab.py`. The [video](#Infrastructure-Summary) linked above shows you how to use the script as well.\n",
    "\n",
    "Once `python lab-validation.py` shows that you're passing all test cases, you're ready to submit your `lab.py` (and only your `lab.py`) to Gradescope. Once submitting to Gradescope, make sure to stick around until all test cases pass.\n",
    "\n",
    "There is also a call to `grader.check_all()` below in _this_ notebook, but make sure to also follow the steps above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "otter": {
   "tests": {
    "q0": {
     "name": "q0",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> consecutive_ints([5, 3, 6, 4, 9, 8])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> consecutive_ints([1, 3, 5, 7, 9]) == False\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> consecutive_ints([]) == False\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> median_vs_mean([6, 5, 4, 3, 2])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> median_vs_mean([50, 20, 15, 40])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> median_vs_mean([1, 8, 9]) == False\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> n_prefixes('Billy', 4) == 'BillBilBiB'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> n_prefixes('Marina', 3) == 'MarMaM'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> n_prefixes('aaron', 2) == 'aaa'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> n_prefixes('Justin', 5) == 'JustiJustJusJuJ'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> exploded_numbers([3, 8, 15], 2) == ['01 02 03 04 05', '06 07 08 09 10', '13 14 15 16 17']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> exploded_numbers([9, 99], 3) == ['006 007 008 009 010 011 012', '096 097 098 099 100 101 102']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> fp = Path('data') / 'chars.txt'\n>>> last_chars(open(fp)) == 'hrg'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(out_1, np.ndarray)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.all(out_1 >= A_1)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(out_1[3], 7 + np.sqrt(3))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(out_2, np.ndarray)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_2.dtype == np.dtype('bool')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_2[2]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> a = np.array([[1,-2, 3,-3], [0, 1, 3, 6]])\n>>> len(filter_cutoff_loop(a, 1).shape)==2\nTrue",
         "failure_message": "should return a 2-dimensional numpy array",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> a = np.array([[1,-2, 3,-3], [0, 1, 3, 6]])\n>>> isinstance(filter_cutoff_loop(a, 1), np.ndarray)\nTrue",
         "failure_message": "the data type returned should be a numpy array",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6.2": {
     "name": "q6.2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> a = np.array([[1,-2, 3,-3], [0, 1, 3, 6]])\n>>> len(filter_cutoff_np(a, 1).shape)==2\nTrue",
         "failure_message": "should return a 2-dimensional numpy array",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> a = np.array([[1,-2, 3,-3], [0, 1, 3, 6]])\n>>> isinstance(filter_cutoff_np(a, 1), np.ndarray)\nTrue",
         "failure_message": "the data type returned should be a numpy array",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out_3_stocks.dtype == np.dtype('float')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_3_stocks.max() == 0.03\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> import numbers\n>>> isinstance(out_4, numbers.Integral)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_4 == 1\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(stats, pd.Series)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 'total_highest' in stats.index\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(stats.loc['duplicates'], bool) or isinstance(stats.loc['duplicates'], np.bool_)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> list(df.columns) == cols\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> df['last'].dtype == np.dtype('O')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> df['height'].dtype == np.dtype('float64')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> df['geo'].str.contains(',').all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(df) == 100\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> dg.index = range(9, 13)\n>>> (dg == df.iloc[9:13]).all().all()\nTrue",
         "failure_message": "doctest examples",
         "hidden": false,
         "locked": false,
         "points": 6
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
